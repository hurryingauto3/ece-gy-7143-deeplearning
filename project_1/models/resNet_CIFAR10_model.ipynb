{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colabcode import ColabCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We set different training hyper parameters that are required for ResNet architecture. We also perform some preprocessing on our dataset to prepare it for training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "subtract_pixel_mean = True\n",
    "n = 3\n",
    "version = 1\n",
    "\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "model_type = 'ResNet % dv % d' % (depth, version)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we set the learning rate according to the number of epochs. As the number of epochs the learning rate must be decreased to ensure better learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (843913916.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    if epoch &gt; 180:\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch &gt; 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch &gt; 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch &gt; 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch &gt; 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, lr_schedule, adjusts the learning rate based on the current training epoch. It starts with a base learning rate of 0.001 (1e-3). As the number of epochs increases, the learning rate decreases step by step: after 80 epochs, it becomes 0.0001 (10 times smaller), after 120 epochs, it reduces further to 0.00001, and so on.\n",
    "\n",
    "This gradual decrease helps the model make smaller updates to fine-tune its learning as training progresses. The function also prints the current learning rate so you can track how it’s changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining basic ResNet building block that can be used for defining the ResNet V1 and V2 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resnet_layer function creates a ResNet layer with a convolution (Conv2D), optional batch normalization, and activation (e.g., ReLU). The order of these operations depends on the conv_first flag, making it flexible for building ResNet architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10): \n",
    "    if (depth - 2) % 6 != 0: \n",
    "        raise ValueError('depth should be 6n + 2 (eg 20, 32, 44 in [a])') \n",
    "\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6) \n",
    "\n",
    "    inputs = Input(shape=input_shape) \n",
    "    x = resnet_layer(inputs=inputs) \n",
    "\n",
    "    for stack in range(3): \n",
    "        for res_block in range(num_res_blocks): \n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0: \n",
    "                strides = 2 \n",
    "            y = resnet_layer(inputs=x, \n",
    "                             num_filters=num_filters, \n",
    "                             strides=strides) \n",
    "            y = resnet_layer(inputs=y, \n",
    "                             num_filters=num_filters, \n",
    "                             activation=None) \n",
    "            if stack > 0 and res_block == 0: \n",
    "                x = resnet_layer(inputs=x, \n",
    "                                 num_filters=num_filters, \n",
    "                                 kernel_size=1, \n",
    "                                 strides=strides, \n",
    "                                 activation=None, \n",
    "                                 batch_normalization=False) \n",
    "            x = keras.layers.add([x, y]) \n",
    "            x = Activation('relu')(x) \n",
    "        num_filters *= 2\n",
    "\n",
    "    x = AveragePooling2D(pool_size=8)(x) \n",
    "    y = Flatten()(x) \n",
    "    outputs = Dense(num_classes, \n",
    "                    activation='softmax', \n",
    "                    kernel_initializer='he_normal')(y) \n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define ResNet V2 architecture that is based on the ResNet building block we defined above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n + 2 (eg 56 or 110 in [b])')\n",
    "\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:\n",
    "                    strides = 2\n",
    "\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements ResNet V2, a deep residual network with bottleneck blocks, batch normalization, and ReLU before convolutions. It efficiently downsamples inputs, ending with global average pooling and a softmax classifier for robust training of deep models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The code below is used to train and test the ResNet v1 and v2 architecture we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if version == 2: \n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth) \n",
    "else: \n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=lr_schedule(0)), \n",
    "              metrics=['accuracy']) \n",
    "model.summary() \n",
    "print(model_type)\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models') \n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.keras' % model_type \n",
    "if not os.path.isdir(save_dir): \n",
    "    os.makedirs(save_dir) \n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                              monitor='val_acc', \n",
    "                              verbose=1, \n",
    "                              save_best_only=True) \n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule) \n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), \n",
    "                               cooldown=0, \n",
    "                               patience=5, \n",
    "                               min_lr=0.5e-6) \n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler] \n",
    "\n",
    "if not data_augmentation: \n",
    "    print('Not using data augmentation.') \n",
    "    model.fit(x_train, y_train, \n",
    "              batch_size=batch_size, \n",
    "              epochs=epochs, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True, \n",
    "              callbacks=callbacks) \n",
    "else: \n",
    "    print('Using real-time data augmentation.') \n",
    "    datagen = ImageDataGenerator(\n",
    "        feat\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
