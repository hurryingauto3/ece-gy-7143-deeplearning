{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:18:58.773642Z",
     "iopub.status.busy": "2025-04-15T00:18:58.773088Z",
     "iopub.status.idle": "2025-04-15T00:19:01.858105Z",
     "shell.execute_reply": "2025-04-15T00:19:01.857178Z",
     "shell.execute_reply.started": "2025-04-15T00:18:58.773617Z"
    },
    "id": "YQkw3v907vn6",
    "outputId": "c9f5588d-e1bc-456a-de53-cc678024ec6b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:01.860039Z",
     "iopub.status.busy": "2025-04-15T00:19:01.859797Z",
     "iopub.status.idle": "2025-04-15T00:19:01.870447Z",
     "shell.execute_reply": "2025-04-15T00:19:01.869889Z",
     "shell.execute_reply.started": "2025-04-15T00:19:01.860011Z"
    },
    "id": "WXlsSvXjqrpb",
    "outputId": "09bc76f2-b818-4757-c8f9-a7da35f48e0f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define Kaggle credentials\n",
    "kaggle_creds = {\n",
    "    \"username\": \"hurryingauto3\",\n",
    "    \"key\": \"17e33c07cfd0993aecbc770b33c7054e\"\n",
    "}\n",
    "\n",
    "# Ensure the Kaggle config directory exists\n",
    "os.makedirs(os.path.expanduser(\"~/.config/kaggle/\"), exist_ok=True)\n",
    "\n",
    "# Write credentials to kaggle.json\n",
    "with open(os.path.expanduser(\"~/.config/kaggle/kaggle.json\"), \"w\") as f:\n",
    "    json.dump(kaggle_creds, f)\n",
    "\n",
    "# Set correct permissions\n",
    "os.chmod(os.path.expanduser(\"~/.config/kaggle/kaggle.json\"), 0o600)\n",
    "\n",
    "# Remove the \"data/\" directory if it exists\n",
    "os.system(\"rm -rf data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:01.871814Z",
     "iopub.status.busy": "2025-04-15T00:19:01.871183Z",
     "iopub.status.idle": "2025-04-15T00:19:25.357853Z",
     "shell.execute_reply": "2025-04-15T00:19:25.356830Z",
     "shell.execute_reply.started": "2025-04-15T00:19:01.871796Z"
    },
    "id": "W8PGM0LwApq0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "try:\n",
    "    from datasets import Dataset as HFDataset # Use an alias to avoid conflict with torch.utils.data.Dataset\n",
    "    from datasets import load_dataset\n",
    "except ImportError:\n",
    "    print(\"Please install the 'datasets' library: pip install datasets\")\n",
    "    HFDataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:25.361440Z",
     "iopub.status.busy": "2025-04-15T00:19:25.360455Z",
     "iopub.status.idle": "2025-04-15T00:19:25.396747Z",
     "shell.execute_reply": "2025-04-15T00:19:25.395754Z",
     "shell.execute_reply.started": "2025-04-15T00:19:25.361407Z"
    },
    "id": "i-y0FkhJp-kG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Custom Dataset for the Competition Test File ---\n",
    "class AGNewsTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for AGNEWS competition test text data.\n",
    "    Handles test data stored as a pickled Hugging Face Dataset object.\n",
    "\n",
    "    Args:\n",
    "        pkl_file (str): Path to the pickle file containing the test data (expected as HF Dataset).\n",
    "        tokenizer (callable): Tokenizer instance (e.g., from Hugging Face)\n",
    "        max_length (int): Maximum sequence length for tokenization.\n",
    "        text_column (str): The name of the column containing the text in the pickled Dataset. Defaults to 'text'.\n",
    "    \"\"\"\n",
    "    def __init__(self, pkl_file, tokenizer, max_length=512, text_column=\"text\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.text_column = text_column\n",
    "        self.texts = [] # Initialize as empty list\n",
    "\n",
    "        try:\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                loaded_object = pickle.load(f)\n",
    "\n",
    "            # --- Check if the loaded object is a Hugging Face Dataset ---\n",
    "            if HFDataset is not None and isinstance(loaded_object, HFDataset):\n",
    "                print(f\"Pickle file contained a Hugging Face Dataset object.\")\n",
    "                # Check if the expected text column exists\n",
    "                if self.text_column in loaded_object.column_names:\n",
    "                    # Extract the text column into a list\n",
    "                    self.texts = loaded_object[self.text_column]\n",
    "                    print(f\"Successfully extracted '{self.text_column}' column ({len(self.texts)} items).\")\n",
    "                else:\n",
    "                    raise ValueError(f\"Loaded Dataset object does not contain the expected text column '{self.text_column}'. \"\n",
    "                                     f\"Available columns: {loaded_object.column_names}\")\n",
    "            # --- Fallback: Check if it's a list (original assumption) ---\n",
    "            elif isinstance(loaded_object, list):\n",
    "                 print(\"Pickle file contained a standard Python list.\")\n",
    "                 self.texts = loaded_object\n",
    "            # --- Fallback: Check if it's a dictionary (previous check) ---\n",
    "            elif isinstance(loaded_object, dict):\n",
    "                 print(\"Pickle file contained a standard Python dict.\")\n",
    "                 possible_keys = ['text', 'data', 'description'] # Add other likely keys if needed\n",
    "                 data_key = next((k for k in possible_keys if k in loaded_object), None)\n",
    "                 if data_key and isinstance(loaded_object[data_key], list):\n",
    "                     print(f\"Assuming text data is under key '{data_key}'.\")\n",
    "                     self.texts = loaded_object[data_key]\n",
    "                 else:\n",
    "                     raise ValueError(f\"Could not find a list of texts in pkl dictionary. Keys found: {list(loaded_object.keys())}\")\n",
    "            # --- If none of the above ---\n",
    "            else:\n",
    "                 raise TypeError(f\"Unsupported data type loaded from pickle file: {type(loaded_object)}. \"\n",
    "                                 \"Expected Hugging Face Dataset, list, or dict containing a list.\")\n",
    "\n",
    "            # Final check if texts were actually loaded\n",
    "            if not self.texts:\n",
    "                 raise ValueError(f\"Failed to load any text data from the pickle file: {pkl_file}\")\n",
    "\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Test pickle file not found at {pkl_file}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing pickle file {pkl_file}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        # Ensure text is a string (might be redundant if extracted from HF Dataset, but safe)\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=False, # Padding will be handled by the collator\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=None, # Return python lists/ints, collator handles tensor conversion\n",
    "        )\n",
    "\n",
    "        # Return the tokenized inputs and the original index for submission mapping\n",
    "        # Remove 'token_type_ids' if your model doesn't use them (like RoBERTa)\n",
    "        item = {k: v for k, v in encoding.items() if k != 'token_type_ids'}\n",
    "        item['index'] = index # Include original index\n",
    "\n",
    "        return item\n",
    "\n",
    "# --- Data Module for AGNEWS ---\n",
    "class AGNewsDataModule:\n",
    "    \"\"\"\n",
    "    Data module for AGNEWS dataset (train/val from Hugging Face, test from competition file).\n",
    "\n",
    "    Args:\n",
    "        model_name_or_path (str): Identifier for the tokenizer (e.g., \"roberta-base\").\n",
    "        data_dir (str): Directory to potentially store data (less critical when using `datasets`).\n",
    "        competition_name (str): Name of the Kaggle competition for downloading test data.\n",
    "        batch_size (int): Training batch size.\n",
    "        test_batch_size (int): Testing/Validation batch size.\n",
    "        num_workers (int): Number of workers for data loading.\n",
    "        max_seq_length (int): Maximum sequence length for tokenizer.\n",
    "        val_split_percentage (float): Percentage of training data to use for validation (0 to disable).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model_name_or_path=\"roberta-base\",\n",
    "                 data_dir=\"./data_agnews\",\n",
    "                 competition_name=\"deep-learning-spring-2025-project-2\", # UPDATE IF NEEDED\n",
    "                 batch_size=16,\n",
    "                 test_batch_size=32,\n",
    "                 num_workers=2,\n",
    "                 max_seq_length=512,\n",
    "                 val_split_percentage=0.1): # Use 10% of train for validation\n",
    "\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.data_dir = data_dir\n",
    "        self.competition_name = competition_name\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.val_split_percentage = val_split_percentage\n",
    "\n",
    "        # Paths for competition data\n",
    "        self.competition_path = os.path.join(self.data_dir, self.competition_name)\n",
    "        self.zip_path = os.path.join(self.competition_path, f\"{self.competition_name}.zip\")\n",
    "        self.test_pkl = os.path.join(self.competition_path, \"test_unlabelled.pkl\") # Correct filename\n",
    "\n",
    "        # Initialize tokenizer and data collator\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "        # Data collator handles dynamic padding within each batch\n",
    "        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        self.predict_dataset = None\n",
    "\n",
    "    def _tokenize_function(self, examples):\n",
    "        # Tokenize the text field. AGNEWS uses 'text'.\n",
    "        # Padding is false here; collator handles it later.\n",
    "        return self.tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=self.max_seq_length\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Downloads competition data if needed.\"\"\"\n",
    "        # Download standard AGNEWS train/test via `datasets` library automatically on first use.\n",
    "        print(\"Checking/downloading AGNEWS dataset from Hugging Face...\")\n",
    "        load_dataset(\"ag_news\", cache_dir=os.path.join(self.data_dir, \"hf_cache\"))\n",
    "        print(\"Checking/downloading competition test data...\")\n",
    "        self.download_competition_data()\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Loads and preprocesses datasets.\"\"\"\n",
    "        # Load AGNEWS dataset\n",
    "        dataset = load_dataset(\"ag_news\", cache_dir=os.path.join(self.data_dir, \"hf_cache\"))\n",
    "\n",
    "        # Tokenize dataset\n",
    "        tokenized_dataset = dataset.map(self._tokenize_function, batched=True)\n",
    "\n",
    "        # Remove original text column, select necessary columns\n",
    "        tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "        # Rename 'label' to 'labels' if required by the model/trainer framework\n",
    "        # tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "        tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            ag_train_data = tokenized_dataset[\"train\"]\n",
    "            if self.val_split_percentage > 0:\n",
    "                split = ag_train_data.train_test_split(test_size=self.val_split_percentage)\n",
    "                self.train_dataset = split['train']\n",
    "                self.val_dataset = split['test']\n",
    "                print(f\"Using {len(self.train_dataset)} samples for training, {len(self.val_dataset)} for validation.\")\n",
    "            else:\n",
    "                # Use standard AGNEWS test set as validation if no split % is given\n",
    "                self.train_dataset = ag_train_data\n",
    "                self.val_dataset = tokenized_dataset[\"test\"]\n",
    "                print(f\"Using {len(self.train_dataset)} samples for training, {len(self.val_dataset)} (standard test set) for validation.\")\n",
    "\n",
    "\n",
    "        if stage == \"validate\" or stage is None:\n",
    "             if self.val_dataset is None: # If setup wasn't called with 'fit'\n",
    "                 # Load validation data (standard AGNEWS test set)\n",
    "                 self.val_dataset = tokenized_dataset[\"test\"]\n",
    "                 print(f\"Loaded {len(self.val_dataset)} (standard test set) for validation.\")\n",
    "\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            # Setup competition test dataset\n",
    "             print(f\"Setting up competition test dataset from: {self.test_pkl}\")\n",
    "             self.predict_dataset = AGNewsTestDataset(\n",
    "                 self.test_pkl,\n",
    "                 self.tokenizer,\n",
    "                 self.max_seq_length\n",
    "             )\n",
    "             print(f\"Loaded {len(self.predict_dataset)} samples for competition prediction.\")\n",
    "\n",
    "\n",
    "    def get_train_loader(self):\n",
    "        if not self.train_dataset:\n",
    "            self.setup(\"fit\")\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.data_collator # Use collator for dynamic padding\n",
    "        )\n",
    "\n",
    "    def get_val_loader(self):\n",
    "        if not self.val_dataset:\n",
    "            self.setup(\"validate\") # Or 'fit' if you always run setup completely\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.data_collator # Use collator for dynamic padding\n",
    "        )\n",
    "\n",
    "    def get_competition_test_loader(self):\n",
    "        \"\"\"Gets the DataLoader for the competition's unlabelled test set.\"\"\"\n",
    "        if not self.predict_dataset:\n",
    "            self.setup(\"test\")\n",
    "        return DataLoader(\n",
    "            self.predict_dataset,\n",
    "            batch_size=self.test_batch_size,\n",
    "            shuffle=False, # Important: Keep order for submission\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.data_collator # Use collator for dynamic padding - it handles dicts well\n",
    "        )\n",
    "\n",
    "    def download_competition_data(self):\n",
    "        \"\"\"Downloads and extracts competition test data using Kaggle API.\"\"\"\n",
    "        if not os.path.exists(self.test_pkl):\n",
    "            print(f\"Competition test file not found at {self.test_pkl}. Attempting download...\")\n",
    "            os.makedirs(self.competition_path, exist_ok=True)\n",
    "            try:\n",
    "                from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "                api = KaggleApi()\n",
    "                api.authenticate() # Make sure kaggle.json is set up\n",
    "                api.competition_download_files(self.competition_name, path=self.competition_path)\n",
    "\n",
    "                if os.path.exists(self.zip_path):\n",
    "                    print(f\"Extracting {self.zip_path}...\")\n",
    "                    with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(self.competition_path)\n",
    "                    os.remove(self.zip_path) # Clean up the zip file\n",
    "                    print(\"Extraction complete.\")\n",
    "                else:\n",
    "                     print(f\"Warning: Zip file {self.zip_path} not found after download attempt.\")\n",
    "\n",
    "            except ImportError:\n",
    "                print(\"Warning: 'kaggle' library not found. Cannot download competition data automatically.\")\n",
    "                print(\"Please download the 'test_unlabelled.pkl' manually from the Kaggle competition page\")\n",
    "                print(f\"and place it in: {self.competition_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during Kaggle download/extraction: {e}\")\n",
    "                print(\"Please check your Kaggle API setup and competition name.\")\n",
    "\n",
    "        if not os.path.exists(self.test_pkl):\n",
    "            # Raise error only after attempting download\n",
    "            raise FileNotFoundError(\n",
    "                f\"Competition test file '{os.path.basename(self.test_pkl)}' not found in '{self.competition_path}'. \"\n",
    "                \"Please ensure it is downloaded and extracted correctly.\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Competition test file found: {self.test_pkl}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:25.398087Z",
     "iopub.status.busy": "2025-04-15T00:19:25.397803Z",
     "iopub.status.idle": "2025-04-15T00:19:57.859079Z",
     "shell.execute_reply": "2025-04-15T00:19:57.858317Z",
     "shell.execute_reply.started": "2025-04-15T00:19:25.398063Z"
    },
    "id": "VBzMLw2oxvXV",
    "outputId": "c68f6fa7-30f5-42f4-ddf7-1bcff2847642",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"roberta-base\"\n",
    "COMPETITION_ID = \"deep-learning-spring-2025-project-2\" # Double-check this ID\n",
    "DATA_DIR = \"./agnews_data\"\n",
    "BATCH_SIZE = 8 # Small batch size for demo\n",
    "TEST_BATCH_SIZE = 16\n",
    "MAX_LEN = 128 # Shorter length for faster demo processing\n",
    "\n",
    "# Instantiate the data module\n",
    "data_module = AGNewsDataModule(\n",
    "    model_name_or_path=MODEL_ID,\n",
    "    data_dir=DATA_DIR,\n",
    "    competition_name=COMPETITION_ID,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    test_batch_size=TEST_BATCH_SIZE,\n",
    "    max_seq_length=MAX_LEN,\n",
    "    num_workers=2 # Set to 0 for easier debugging in __main__\n",
    ")\n",
    "\n",
    "data_module.prepare_data() # Downloads HF data and competition data if needed\n",
    "\n",
    "data_module.setup() # Sets up train, val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:57.860412Z",
     "iopub.status.busy": "2025-04-15T00:19:57.860165Z",
     "iopub.status.idle": "2025-04-15T00:19:57.915879Z",
     "shell.execute_reply": "2025-04-15T00:19:57.915238Z",
     "shell.execute_reply.started": "2025-04-15T00:19:57.860387Z"
    },
    "id": "kczrZ0BWqy1H",
    "outputId": "8ffa5f1a-0793-4ae1-8813-200b1a12e339",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Visualize Training Samples ---\n",
    "print(\"\\n--- Train Set Samples (First 5) ---\")\n",
    "try:\n",
    "    if data_module.train_dataset:\n",
    "        # Select the first 5 samples directly from the Hugging Face dataset\n",
    "        train_samples = data_module.train_dataset.select(range(min(5, len(data_module.train_dataset))))\n",
    "\n",
    "        train_data_for_df = []\n",
    "        for sample in train_samples:\n",
    "            text = data_module.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "            # Ensure 'label' exists, otherwise use a placeholder like None or -1\n",
    "            label = sample.get('label', None)\n",
    "            if isinstance(label, torch.Tensor):\n",
    "                  label = label.item() # Convert tensor to Python number\n",
    "            train_data_for_df.append({'Decoded Text': text, 'Label': label})\n",
    "\n",
    "        train_df = pd.DataFrame(train_data_for_df)\n",
    "        print(train_df)\n",
    "    else:\n",
    "        print(\"Train dataset not loaded or empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying train samples: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:57.916973Z",
     "iopub.status.busy": "2025-04-15T00:19:57.916718Z",
     "iopub.status.idle": "2025-04-15T00:19:57.933101Z",
     "shell.execute_reply": "2025-04-15T00:19:57.932369Z",
     "shell.execute_reply.started": "2025-04-15T00:19:57.916953Z"
    },
    "id": "C5djOy67q50y",
    "outputId": "48dc22e6-172f-4b39-97e1-d4a293471e06",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Visualize Validation Samples ---\n",
    "print(\"\\n--- Validation Set Samples (First 5) ---\")\n",
    "try:\n",
    "    if data_module.val_dataset:\n",
    "        # Select the first 5 samples directly from the Hugging Face dataset\n",
    "        val_samples = data_module.val_dataset.select(range(min(5, len(data_module.val_dataset))))\n",
    "\n",
    "        val_data_for_df = []\n",
    "        for sample in val_samples:\n",
    "            text = data_module.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "            # Ensure 'label' exists, otherwise use a placeholder like None or -1\n",
    "            label = sample.get('label', None)\n",
    "            if isinstance(label, torch.Tensor):\n",
    "                  label = label.item() # Convert tensor to Python number\n",
    "            val_data_for_df.append({'Decoded Text': text, 'Label': label})\n",
    "\n",
    "        val_df = pd.DataFrame(val_data_for_df)\n",
    "        print(val_df)\n",
    "    else:\n",
    "        print(\"Validation dataset not loaded or empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying validation samples: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:57.934286Z",
     "iopub.status.busy": "2025-04-15T00:19:57.934018Z",
     "iopub.status.idle": "2025-04-15T00:19:57.947271Z",
     "shell.execute_reply": "2025-04-15T00:19:57.946658Z",
     "shell.execute_reply.started": "2025-04-15T00:19:57.934265Z"
    },
    "id": "0rNQ9-6Eq-gk",
    "outputId": "6b052198-c3c9-4976-f10a-2bd78c317abd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Visualize Competition Test Samples ---\n",
    "print(\"\\n--- Competition Test Set Samples (First 5) ---\")\n",
    "try:\n",
    "    if data_module.predict_dataset:\n",
    "        test_data_for_df = []\n",
    "        # Iterate through the custom dataset using __getitem__\n",
    "        num_samples_to_show = min(5, len(data_module.predict_dataset))\n",
    "        for i in range(num_samples_to_show):\n",
    "            sample = data_module.predict_dataset[i] # Fetches the dictionary item\n",
    "            text = data_module.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "            # Ensure 'index' exists, otherwise use a placeholder like None or -1\n",
    "            original_index = sample.get('index', None)\n",
    "            test_data_for_df.append({'Decoded Text': text, 'Original Index': original_index})\n",
    "\n",
    "        test_df = pd.DataFrame(test_data_for_df)\n",
    "        print(test_df)\n",
    "    else:\n",
    "        print(\"Competition test dataset not loaded or empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error displaying competition test samples: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:19:57.948293Z",
     "iopub.status.busy": "2025-04-15T00:19:57.948062Z",
     "iopub.status.idle": "2025-04-15T00:20:05.584197Z",
     "shell.execute_reply": "2025-04-15T00:20:05.583321Z",
     "shell.execute_reply.started": "2025-04-15T00:19:57.948276Z"
    },
    "id": "htBNx68lqdrr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import evaluate # Hugging Face evaluate library\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding # Make sure this is imported\n",
    ")\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nH5s2T44wRIR",
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuSShyAL8SVp"
   },
   "source": [
    "# Bse RoBERTa Model Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:05.587581Z",
     "iopub.status.busy": "2025-04-15T00:20:05.586956Z",
     "iopub.status.idle": "2025-04-15T00:20:05.592594Z",
     "shell.execute_reply": "2025-04-15T00:20:05.591786Z",
     "shell.execute_reply.started": "2025-04-15T00:20:05.587520Z"
    },
    "id": "c77caa05",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Assume AGNewsDataModule is defined in another file or earlier in the script\n",
    "# from your_data_module_file import AGNewsDataModule\n",
    "\n",
    "# --- Configuration ---\n",
    "model_name = \"roberta-base\"\n",
    "num_labels = 4\n",
    "lora_r = 8\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "target_modules = [\"query\", \"value\"]\n",
    "output_dir = \"./results/roberta-lora-agnews\" # Directory to save checkpoints and logs\n",
    "training_log_dir = \"./logs/roberta-lora-agnews\" # Directory for TensorBoard/logging\n",
    "adapter_save_dir = \"./trained_adapters/roberta-lora-agnews\" # Directory to save final adapter\n",
    "\n",
    "# --- Hyperparameters for Training ---\n",
    "# These are crucial and require tuning!\n",
    "learning_rate = 2e-4 # LoRA might tolerate/need higher LR than full finetuning\n",
    "train_batch_size = 16 # Adjust based on GPU memory\n",
    "eval_batch_size = 32  # Adjust based on GPU memory\n",
    "num_train_epochs = 3  # Start with a few epochs, increase as needed\n",
    "weight_decay = 0.01\n",
    "warmup_ratio = 0.1 # Percentage of steps for learning rate warmup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:05.593956Z",
     "iopub.status.busy": "2025-04-15T00:20:05.593658Z",
     "iopub.status.idle": "2025-04-15T00:20:08.323026Z",
     "shell.execute_reply": "2025-04-15T00:20:08.322301Z",
     "shell.execute_reply.started": "2025-04-15T00:20:05.593930Z"
    },
    "id": "dfoSRkq9wTa3",
    "outputId": "f3c3ab22-c527-4987-a1d8-723faedb03b0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Load Base Model (as you did) ---\n",
    "print(f\"Loading base model '{model_name}'...\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:08.324229Z",
     "iopub.status.busy": "2025-04-15T00:20:08.323966Z",
     "iopub.status.idle": "2025-04-15T00:20:08.328365Z",
     "shell.execute_reply": "2025-04-15T00:20:08.327832Z",
     "shell.execute_reply.started": "2025-04-15T00:20:08.324207Z"
    },
    "id": "mBfFThOjwfqI",
    "outputId": "5070a73b-7cef-4ad2-c5a3-506de067b618",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 2. Define LoRA Config (as you did) ---\n",
    "print(\"Defining LoRA configuration...\")\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:08.329395Z",
     "iopub.status.busy": "2025-04-15T00:20:08.329140Z",
     "iopub.status.idle": "2025-04-15T00:20:08.401975Z",
     "shell.execute_reply": "2025-04-15T00:20:08.401389Z",
     "shell.execute_reply.started": "2025-04-15T00:20:08.329372Z"
    },
    "id": "5VcoHYepwXKk",
    "outputId": "64e5aa3f-6b05-4475-adce-570900b03d13",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 3. Apply LoRA to the model (as you did) ---\n",
    "print(\"Applying LoRA adapter to the model...\")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters() # Verify parameter count is low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:08.403242Z",
     "iopub.status.busy": "2025-04-15T00:20:08.402693Z",
     "iopub.status.idle": "2025-04-15T00:20:08.407020Z",
     "shell.execute_reply": "2025-04-15T00:20:08.406273Z",
     "shell.execute_reply.started": "2025-04-15T00:20:08.403220Z"
    },
    "id": "pVhzY7DawXTN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = data_module.get_train_loader().dataset # Get the underlying Dataset object\n",
    "val_dataset = data_module.get_val_loader().dataset     # Get the underlying Dataset object\n",
    "tokenizer = data_module.tokenizer                     # Get the tokenizer\n",
    "data_collator = data_module.data_collator             # Get the data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:08.408191Z",
     "iopub.status.busy": "2025-04-15T00:20:08.407945Z",
     "iopub.status.idle": "2025-04-15T00:20:08.422197Z",
     "shell.execute_reply": "2025-04-15T00:20:08.421592Z",
     "shell.execute_reply.started": "2025-04-15T00:20:08.408169Z"
    },
    "id": "WC_gG7Eewqqw",
    "outputId": "41aae974-7ef4-4345-e47d-2fe5eefde9a4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:08.422966Z",
     "iopub.status.busy": "2025-04-15T00:20:08.422791Z",
     "iopub.status.idle": "2025-04-15T00:20:08.991251Z",
     "shell.execute_reply": "2025-04-15T00:20:08.990782Z",
     "shell.execute_reply.started": "2025-04-15T00:20:08.422953Z"
    },
    "id": "UzAGnMFQwXY7",
    "outputId": "a7ebfdf5-30fd-4569-9df9-5bd3ad9fbcc3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 5. Define Compute Metrics Function ---\n",
    "# Load the accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on evaluation predictions.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # 'predictions' are logits, convert to predicted class index\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)\n",
    "    return {\"accuracy\": acc[\"accuracy\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:08.992205Z",
     "iopub.status.busy": "2025-04-15T00:20:08.991943Z",
     "iopub.status.idle": "2025-04-15T00:20:09.019266Z",
     "shell.execute_reply": "2025-04-15T00:20:09.018787Z",
     "shell.execute_reply.started": "2025-04-15T00:20:08.992182Z"
    },
    "id": "6MMBr27LwXb4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 6. Define Training Arguments ---\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "\n",
    "    # Evaluation and Saving Strategy\n",
    "    eval_strategy=\"epoch\", # Evaluate at the end of each epoch\n",
    "    save_strategy=\"epoch\",       # Save checkpoint at the end of each epoch\n",
    "    load_best_model_at_end=True, # Load the best model found during training\n",
    "    metric_for_best_model=\"accuracy\", # Use accuracy to determine the best model\n",
    "    greater_is_better=True,      # Higher accuracy is better\n",
    "\n",
    "    # Logging\n",
    "    logging_dir=training_log_dir,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,            # Log metrics every 50 steps\n",
    "\n",
    "    # Other potentially useful args\n",
    "    # fp16=True,                 # Enable mixed precision training if GPU supports it (requires accelerate)\n",
    "    # gradient_accumulation_steps=2, # If batch size needs to be effectively larger than fits in memory\n",
    "    report_to=\"tensorboard\",     # Report logs to TensorBoard (can also use \"wandb\")\n",
    "    save_total_limit=2,          # Keep only the last 2 checkpoints + the best one\n",
    "    # push_to_hub=False,         # Set to True to push model to Hugging Face Hub\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:09.020076Z",
     "iopub.status.busy": "2025-04-15T00:20:09.019909Z",
     "iopub.status.idle": "2025-04-15T00:20:09.605934Z",
     "shell.execute_reply": "2025-04-15T00:20:09.605306Z",
     "shell.execute_reply.started": "2025-04-15T00:20:09.020064Z"
    },
    "id": "sXmDmEkawXfL",
    "outputId": "1523e2d1-ca8f-4380-e453-eeb4ffa9a61e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 7. Initialize Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The PEFT model\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=val_dataset,            # Validation dataset\n",
    "    tokenizer=tokenizer,                 # Tokenizer (needed for padding/saving)\n",
    "    data_collator=data_collator,         # Data collator for dynamic padding\n",
    "    compute_metrics=compute_metrics,     # Function to compute metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T00:20:09.606919Z",
     "iopub.status.busy": "2025-04-15T00:20:09.606660Z",
     "iopub.status.idle": "2025-04-15T01:00:36.863223Z",
     "shell.execute_reply": "2025-04-15T01:00:36.862423Z",
     "shell.execute_reply.started": "2025-04-15T00:20:09.606900Z"
    },
    "id": "vBfHlfaZwXib",
    "outputId": "f4a6b747-2684-4063-8b5d-24b93691f784",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 8. Start Training ---\n",
    "print(\"\\nStarting Training...\")\n",
    "train_result = trainer.train()\n",
    "# --- 9. Save Training Stats and Final Adapter ---\n",
    "print(\"\\nTraining finished. Saving metrics and final adapter...\")\n",
    "# Saves metrics like loss, learning rate, epoch, etc. to json file\n",
    "trainer.log_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_metrics(\"train\", train_result.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:00:36.864259Z",
     "iopub.status.busy": "2025-04-15T01:00:36.864008Z",
     "iopub.status.idle": "2025-04-15T01:00:37.110332Z",
     "shell.execute_reply": "2025-04-15T01:00:37.109759Z",
     "shell.execute_reply.started": "2025-04-15T01:00:36.864242Z"
    },
    "id": "QRx5NzMAxEY4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the trained LoRA adapter weights explicitly\n",
    "# This saves only the adapter weights, which is the goal of PEFT\n",
    "model.save_pretrained(adapter_save_dir)\n",
    "# You might also want to save the tokenizer with the adapter for easy loading later\n",
    "tokenizer.save_pretrained(adapter_save_dir)\n",
    "print(f\"LoRA adapter weights saved to: {adapter_save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:00:37.111268Z",
     "iopub.status.busy": "2025-04-15T01:00:37.111052Z",
     "iopub.status.idle": "2025-04-15T01:01:14.917886Z",
     "shell.execute_reply": "2025-04-15T01:01:14.917382Z",
     "shell.execute_reply.started": "2025-04-15T01:00:37.111252Z"
    },
    "id": "1SKBrfk_wXlS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 10. Evaluate Final Model (Optional but recommended) ---\n",
    "print(\"\\nEvaluating the best model on the validation set...\")\n",
    "eval_metrics = trainer.evaluate(eval_dataset=val_dataset) # Use the same validation set\n",
    "trainer.log_metrics(\"eval\", eval_metrics)\n",
    "trainer.save_metrics(\"eval\", eval_metrics)\n",
    "print(f\"Final Evaluation Metrics: {eval_metrics}\")\n",
    "\n",
    "print(\"\\nLoRA Training Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:20:14.708308Z",
     "iopub.status.busy": "2025-04-15T01:20:14.707654Z",
     "iopub.status.idle": "2025-04-15T01:20:14.714332Z",
     "shell.execute_reply": "2025-04-15T01:20:14.713723Z",
     "shell.execute_reply.started": "2025-04-15T01:20:14.708282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # Import os for path joining if reading metrics from file\n",
    "# import json # Import json if reading metrics from file\n",
    "from tqdm.auto import tqdm # For progress bar\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "from torch.utils.data import DataLoader\n",
    "# Assume AGNewsDataModule and AGNewsTestDataset are defined\n",
    "# from your_data_module_file import AGNewsDataModule, AGNewsTestDataset\n",
    "\n",
    "# --- Configuration ---\n",
    "base_model_name = \"roberta-base\"\n",
    "adapter_path = \"./trained_adapters/roberta-lora-agnews\" # Directory where you saved the adapter\n",
    "num_labels = 4\n",
    "eval_batch_size = 32\n",
    "max_seq_length = 128\n",
    "\n",
    "# --- Determine Accuracy for Filename ---\n",
    "\n",
    "final_accuracy = eval_metrics['eval_accuracy']\n",
    "print(f\"Using final accuracy for filename: {final_accuracy:.4f}\")\n",
    "\n",
    "# --- Set Output Filename ---\n",
    "output_csv_path = f\"submission_acc_{final_accuracy:.4f}.csv\"\n",
    "print(f\"Output file will be saved as: {output_csv_path}\")\n",
    "\n",
    "# --- Device Setup ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:20:43.757137Z",
     "iopub.status.busy": "2025-04-15T01:20:43.756427Z",
     "iopub.status.idle": "2025-04-15T01:20:44.473164Z",
     "shell.execute_reply": "2025-04-15T01:20:44.472590Z",
     "shell.execute_reply.started": "2025-04-15T01:20:43.757106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Load Tokenizer ---\n",
    "print(f\"Loading tokenizer from '{base_model_name}'...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "# --- 2. Load Base Model ---\n",
    "print(f\"Loading base model '{base_model_name}'...\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=num_labels,\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "# --- 3. Load LoRA Adapter Weights ---\n",
    "print(f\"Loading LoRA adapter weights from '{adapter_path}'...\")\n",
    "try:\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    print(\"Successfully loaded LoRA adapter.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PEFT model from {adapter_path}: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 4. Prepare Model for Inference ---\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(\"Model moved to device and set to evaluation mode.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:21:28.442088Z",
     "iopub.status.busy": "2025-04-15T01:21:28.441828Z",
     "iopub.status.idle": "2025-04-15T01:21:57.905855Z",
     "shell.execute_reply": "2025-04-15T01:21:57.905157Z",
     "shell.execute_reply.started": "2025-04-15T01:21:28.442069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "competition_loader = data_module.get_competition_test_loader()\n",
    "print(f\"Test data loaded. Number of batches: {len(competition_loader)}\")\n",
    "\n",
    "# --- 6. Run Inference ---\n",
    "all_predictions = []\n",
    "all_indices = []\n",
    "\n",
    "print(\"\\nStarting prediction loop...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(competition_loader, desc=\"Predicting\"):\n",
    "        model_inputs = {\n",
    "            k: v.to(device) for k, v in batch.items()\n",
    "            if k in tokenizer.model_input_names\n",
    "        }\n",
    "        indices = batch['index'].cpu().numpy()\n",
    "        outputs = model(**model_inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        predictions_np = predictions.cpu().numpy()\n",
    "        all_predictions.extend(predictions_np)\n",
    "        all_indices.extend(indices)\n",
    "print(\"Prediction loop finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:30:53.412125Z",
     "iopub.status.busy": "2025-04-15T01:30:53.411431Z",
     "iopub.status.idle": "2025-04-15T01:30:53.446262Z",
     "shell.execute_reply": "2025-04-15T01:30:53.445599Z",
     "shell.execute_reply.started": "2025-04-15T01:30:53.412102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 7. Create DataFrame and Save CSV ---\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': all_indices,\n",
    "    'Label': all_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:31:04.252780Z",
     "iopub.status.busy": "2025-04-15T01:31:04.251994Z",
     "iopub.status.idle": "2025-04-15T01:31:04.263186Z",
     "shell.execute_reply": "2025-04-15T01:31:04.262430Z",
     "shell.execute_reply.started": "2025-04-15T01:31:04.252751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Merge the two dataframes based on the index columns\n",
    "# We use 'Original Index' from test_df and 'index' from submission_df\n",
    "# 'how=inner' ensures only matching indices are kept (should be all of them)\n",
    "view_df = pd.merge(\n",
    "    test_df,\n",
    "    submission_df,\n",
    "    left_on='Original Index', # Key column in the left DataFrame (test_df)\n",
    "    right_on='ID',         # Key column in the right DataFrame (submission_df)\n",
    "    how='inner'               # Use 'inner' join (safer) or 'left' if test_df is guaranteed complete\n",
    ")\n",
    "\n",
    "# --- Display the Result ---\n",
    "print(\"\\n--- Combined View: Test Text with Predictions ---\")\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_colwidth', 150) # Show more of the text\n",
    "pd.set_option('display.width', 1000)      # Wider display\n",
    "\n",
    "view_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T01:32:27.036467Z",
     "iopub.status.busy": "2025-04-15T01:32:27.036219Z",
     "iopub.status.idle": "2025-04-15T01:32:27.046452Z",
     "shell.execute_reply": "2025-04-15T01:32:27.045887Z",
     "shell.execute_reply.started": "2025-04-15T01:32:27.036449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Saving submission file to '{output_csv_path}'...\")\n",
    "submission_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def submit_to_kaggle(filename, message):\n",
    "#     api = KaggleApi()\n",
    "#     api.authenticate()\n",
    "#     api.competition_submit(filename, f\"{message}\", 'deep-learning-spring-2025-project-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit_to_kaggle(output_csv_path, f\"{final_accuracy:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bd4c455124949af8851895001885897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "168d0e769da64fb1b1948d2e2c2a41f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb89eda85ef44a0593772105b83c1452",
      "placeholder": "",
      "style": "IPY_MODEL_c1b8ac865a15430596dfa74e3bd63d4f",
      "value": "model.safetensors:100%"
     }
    },
    "26ac8e7a161c4be39130e202c65643e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dcc4ea65d52488a8551bac7c90a536d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36f1573e3efe48ebb54ede3764b4e867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a3002edb0464d61a875aa5b95458534": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5397426e71d94b8e8703ac2901de70a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1403e13943d4504b47cb528d9ea8915",
      "max": 4203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f4b9f0c60784614871f2e09c79d102a",
      "value": 4203
     }
    },
    "540202ceae8f47c9ae590b4c71975be0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e591897c9964d18ac6419ed25b8360b",
      "placeholder": "",
      "style": "IPY_MODEL_26ac8e7a161c4be39130e202c65643e2",
      "value": "499M/499M[00:06&lt;00:00,99.0MB/s]"
     }
    },
    "569083f6397c456581d2c6ad0137461e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5da6634312534dbcaa66a349092507cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69fdb4c78f174696b1b34b1d0e51ff0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dec70835e8274587a6b41aa2a4f9e7cf",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5da6634312534dbcaa66a349092507cd",
      "value": 498818054
     }
    },
    "75e19d26df8c4b179af6043e4b9e9960": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c1823dd4d3e41d0913e5708b7c7892e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_168d0e769da64fb1b1948d2e2c2a41f9",
       "IPY_MODEL_69fdb4c78f174696b1b34b1d0e51ff0e",
       "IPY_MODEL_540202ceae8f47c9ae590b4c71975be0"
      ],
      "layout": "IPY_MODEL_569083f6397c456581d2c6ad0137461e"
     }
    },
    "945d105ead994f76befbd0e82dc7795c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6d8c9b2eff24e10910c3ac09eb234b1",
       "IPY_MODEL_c8ac90bb59f949d08f903fbd1a94e5a8",
       "IPY_MODEL_f016b72d72d94010a0f6788251ed2842"
      ],
      "layout": "IPY_MODEL_a2dc9fc7a2ff432db8fbecfa0b691c5d"
     }
    },
    "9e591897c9964d18ac6419ed25b8360b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f16e4c9098e45a2978753774e5e7f44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f4b9f0c60784614871f2e09c79d102a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1403e13943d4504b47cb528d9ea8915": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a237a616f03d4f28b66a34b6dd0bde9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2dc9fc7a2ff432db8fbecfa0b691c5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad8cea3a91ea463cb09818b9526a8d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af827b8ed9824e89b13f570c760277b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf2c736851f64d6d8ca5df2e6629df39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1a52f19f7764667a4738180f82817fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a237a616f03d4f28b66a34b6dd0bde9a",
      "placeholder": "",
      "style": "IPY_MODEL_da5ea0abcecb4fdab4340436589fa0fe",
      "value": "Downloadingbuilderscript:100%"
     }
    },
    "c1b8ac865a15430596dfa74e3bd63d4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c676d3d98aa84b8492e1a74ef8ba7ec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c1a52f19f7764667a4738180f82817fc",
       "IPY_MODEL_5397426e71d94b8e8703ac2901de70a4",
       "IPY_MODEL_f4c4666f185c405b89dd09c98a6480ab"
      ],
      "layout": "IPY_MODEL_2dcc4ea65d52488a8551bac7c90a536d"
     }
    },
    "c8ac90bb59f949d08f903fbd1a94e5a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af827b8ed9824e89b13f570c760277b0",
      "max": 7600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0bd4c455124949af8851895001885897",
      "value": 7600
     }
    },
    "da5ea0abcecb4fdab4340436589fa0fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dec70835e8274587a6b41aa2a4f9e7cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb89eda85ef44a0593772105b83c1452": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f016b72d72d94010a0f6788251ed2842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f16e4c9098e45a2978753774e5e7f44",
      "placeholder": "",
      "style": "IPY_MODEL_36f1573e3efe48ebb54ede3764b4e867",
      "value": "7600/7600[00:01&lt;00:00,5687.18examples/s]"
     }
    },
    "f4c4666f185c405b89dd09c98a6480ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a3002edb0464d61a875aa5b95458534",
      "placeholder": "",
      "style": "IPY_MODEL_75e19d26df8c4b179af6043e4b9e9960",
      "value": "4.20k/4.20k[00:00&lt;00:00,229kB/s]"
     }
    },
    "f6d8c9b2eff24e10910c3ac09eb234b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf2c736851f64d6d8ca5df2e6629df39",
      "placeholder": "",
      "style": "IPY_MODEL_ad8cea3a91ea463cb09818b9526a8d51",
      "value": "Map:100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
