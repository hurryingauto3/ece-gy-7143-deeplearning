{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate"
      ],
      "metadata": {
        "id": "YQkw3v907vn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f5588d-e1bc-456a-de53-cc678024ec6b"
      },
      "id": "YQkw3v907vn6",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define Kaggle credentials\n",
        "kaggle_creds = {\n",
        "    \"username\": \"hurryingauto3\",\n",
        "    \"key\": \"17e33c07cfd0993aecbc770b33c7054e\"\n",
        "}\n",
        "\n",
        "# Ensure the Kaggle config directory exists\n",
        "os.makedirs(os.path.expanduser(\"~/.config/kaggle/\"), exist_ok=True)\n",
        "\n",
        "# Write credentials to kaggle.json\n",
        "with open(os.path.expanduser(\"~/.config/kaggle/kaggle.json\"), \"w\") as f:\n",
        "    json.dump(kaggle_creds, f)\n",
        "\n",
        "# Set correct permissions\n",
        "os.chmod(os.path.expanduser(\"~/.config/kaggle/kaggle.json\"), 0o600)\n",
        "\n",
        "# Remove the \"data/\" directory if it exists\n",
        "os.system(\"rm -rf data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXlsSvXjqrpb",
        "outputId": "09bc76f2-b818-4757-c8f9-a7da35f48e0f"
      },
      "id": "WXlsSvXjqrpb",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import zipfile\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "try:\n",
        "    from datasets import Dataset as HFDataset # Use an alias to avoid conflict with torch.utils.data.Dataset\n",
        "    from datasets import load_dataset\n",
        "except ImportError:\n",
        "    print(\"Please install the 'datasets' library: pip install datasets\")\n",
        "    HFDataset = None\n"
      ],
      "metadata": {
        "id": "W8PGM0LwApq0"
      },
      "id": "W8PGM0LwApq0",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Custom Dataset for the Competition Test File ---\n",
        "class AGNewsTestDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset for AGNEWS competition test text data.\n",
        "    Handles test data stored as a pickled Hugging Face Dataset object.\n",
        "\n",
        "    Args:\n",
        "        pkl_file (str): Path to the pickle file containing the test data (expected as HF Dataset).\n",
        "        tokenizer (callable): Tokenizer instance (e.g., from Hugging Face)\n",
        "        max_length (int): Maximum sequence length for tokenization.\n",
        "        text_column (str): The name of the column containing the text in the pickled Dataset. Defaults to 'text'.\n",
        "    \"\"\"\n",
        "    def __init__(self, pkl_file, tokenizer, max_length=512, text_column=\"text\"):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.text_column = text_column\n",
        "        self.texts = [] # Initialize as empty list\n",
        "\n",
        "        try:\n",
        "            with open(pkl_file, 'rb') as f:\n",
        "                loaded_object = pickle.load(f)\n",
        "\n",
        "            # --- Check if the loaded object is a Hugging Face Dataset ---\n",
        "            if HFDataset is not None and isinstance(loaded_object, HFDataset):\n",
        "                print(f\"Pickle file contained a Hugging Face Dataset object.\")\n",
        "                # Check if the expected text column exists\n",
        "                if self.text_column in loaded_object.column_names:\n",
        "                    # Extract the text column into a list\n",
        "                    self.texts = loaded_object[self.text_column]\n",
        "                    print(f\"Successfully extracted '{self.text_column}' column ({len(self.texts)} items).\")\n",
        "                else:\n",
        "                    raise ValueError(f\"Loaded Dataset object does not contain the expected text column '{self.text_column}'. \"\n",
        "                                     f\"Available columns: {loaded_object.column_names}\")\n",
        "            # --- Fallback: Check if it's a list (original assumption) ---\n",
        "            elif isinstance(loaded_object, list):\n",
        "                 print(\"Pickle file contained a standard Python list.\")\n",
        "                 self.texts = loaded_object\n",
        "            # --- Fallback: Check if it's a dictionary (previous check) ---\n",
        "            elif isinstance(loaded_object, dict):\n",
        "                 print(\"Pickle file contained a standard Python dict.\")\n",
        "                 possible_keys = ['text', 'data', 'description'] # Add other likely keys if needed\n",
        "                 data_key = next((k for k in possible_keys if k in loaded_object), None)\n",
        "                 if data_key and isinstance(loaded_object[data_key], list):\n",
        "                     print(f\"Assuming text data is under key '{data_key}'.\")\n",
        "                     self.texts = loaded_object[data_key]\n",
        "                 else:\n",
        "                     raise ValueError(f\"Could not find a list of texts in pkl dictionary. Keys found: {list(loaded_object.keys())}\")\n",
        "            # --- If none of the above ---\n",
        "            else:\n",
        "                 raise TypeError(f\"Unsupported data type loaded from pickle file: {type(loaded_object)}. \"\n",
        "                                 \"Expected Hugging Face Dataset, list, or dict containing a list.\")\n",
        "\n",
        "            # Final check if texts were actually loaded\n",
        "            if not self.texts:\n",
        "                 raise ValueError(f\"Failed to load any text data from the pickle file: {pkl_file}\")\n",
        "\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Test pickle file not found at {pkl_file}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading or processing pickle file {pkl_file}: {e}\")\n",
        "            raise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        # Ensure text is a string (might be redundant if extracted from HF Dataset, but safe)\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=False, # Padding will be handled by the collator\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=None, # Return python lists/ints, collator handles tensor conversion\n",
        "        )\n",
        "\n",
        "        # Return the tokenized inputs and the original index for submission mapping\n",
        "        # Remove 'token_type_ids' if your model doesn't use them (like RoBERTa)\n",
        "        item = {k: v for k, v in encoding.items() if k != 'token_type_ids'}\n",
        "        item['index'] = index # Include original index\n",
        "\n",
        "        return item\n",
        "\n",
        "# --- Data Module for AGNEWS ---\n",
        "class AGNewsDataModule:\n",
        "    \"\"\"\n",
        "    Data module for AGNEWS dataset (train/val from Hugging Face, test from competition file).\n",
        "\n",
        "    Args:\n",
        "        model_name_or_path (str): Identifier for the tokenizer (e.g., \"roberta-base\").\n",
        "        data_dir (str): Directory to potentially store data (less critical when using `datasets`).\n",
        "        competition_name (str): Name of the Kaggle competition for downloading test data.\n",
        "        batch_size (int): Training batch size.\n",
        "        test_batch_size (int): Testing/Validation batch size.\n",
        "        num_workers (int): Number of workers for data loading.\n",
        "        max_seq_length (int): Maximum sequence length for tokenizer.\n",
        "        val_split_percentage (float): Percentage of training data to use for validation (0 to disable).\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 model_name_or_path=\"roberta-base\",\n",
        "                 data_dir=\"./data_agnews\",\n",
        "                 competition_name=\"deep-learning-spring-2025-project-2\", # UPDATE IF NEEDED\n",
        "                 batch_size=16,\n",
        "                 test_batch_size=32,\n",
        "                 num_workers=2,\n",
        "                 max_seq_length=512,\n",
        "                 val_split_percentage=0.1): # Use 10% of train for validation\n",
        "\n",
        "        self.model_name_or_path = model_name_or_path\n",
        "        self.data_dir = data_dir\n",
        "        self.competition_name = competition_name\n",
        "        self.batch_size = batch_size\n",
        "        self.test_batch_size = test_batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.val_split_percentage = val_split_percentage\n",
        "\n",
        "        # Paths for competition data\n",
        "        self.competition_path = os.path.join(self.data_dir, self.competition_name)\n",
        "        self.zip_path = os.path.join(self.competition_path, f\"{self.competition_name}.zip\")\n",
        "        self.test_pkl = os.path.join(self.competition_path, \"test_unlabelled.pkl\") # Correct filename\n",
        "\n",
        "        # Initialize tokenizer and data collator\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
        "        # Data collator handles dynamic padding within each batch\n",
        "        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.val_dataset = None\n",
        "        self.predict_dataset = None\n",
        "\n",
        "    def _tokenize_function(self, examples):\n",
        "        # Tokenize the text field. AGNEWS uses 'text'.\n",
        "        # Padding is false here; collator handles it later.\n",
        "        return self.tokenizer(\n",
        "            examples[\"text\"],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            max_length=self.max_seq_length\n",
        "        )\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Downloads competition data if needed.\"\"\"\n",
        "        # Download standard AGNEWS train/test via `datasets` library automatically on first use.\n",
        "        print(\"Checking/downloading AGNEWS dataset from Hugging Face...\")\n",
        "        load_dataset(\"ag_news\", cache_dir=os.path.join(self.data_dir, \"hf_cache\"))\n",
        "        print(\"Checking/downloading competition test data...\")\n",
        "        self.download_competition_data()\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"Loads and preprocesses datasets.\"\"\"\n",
        "        # Load AGNEWS dataset\n",
        "        dataset = load_dataset(\"ag_news\", cache_dir=os.path.join(self.data_dir, \"hf_cache\"))\n",
        "\n",
        "        # Tokenize dataset\n",
        "        tokenized_dataset = dataset.map(self._tokenize_function, batched=True)\n",
        "\n",
        "        # Remove original text column, select necessary columns\n",
        "        tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
        "        # Rename 'label' to 'labels' if required by the model/trainer framework\n",
        "        # tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "        tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            ag_train_data = tokenized_dataset[\"train\"]\n",
        "            if self.val_split_percentage > 0:\n",
        "                split = ag_train_data.train_test_split(test_size=self.val_split_percentage)\n",
        "                self.train_dataset = split['train']\n",
        "                self.val_dataset = split['test']\n",
        "                print(f\"Using {len(self.train_dataset)} samples for training, {len(self.val_dataset)} for validation.\")\n",
        "            else:\n",
        "                # Use standard AGNEWS test set as validation if no split % is given\n",
        "                self.train_dataset = ag_train_data\n",
        "                self.val_dataset = tokenized_dataset[\"test\"]\n",
        "                print(f\"Using {len(self.train_dataset)} samples for training, {len(self.val_dataset)} (standard test set) for validation.\")\n",
        "\n",
        "\n",
        "        if stage == \"validate\" or stage is None:\n",
        "             if self.val_dataset is None: # If setup wasn't called with 'fit'\n",
        "                 # Load validation data (standard AGNEWS test set)\n",
        "                 self.val_dataset = tokenized_dataset[\"test\"]\n",
        "                 print(f\"Loaded {len(self.val_dataset)} (standard test set) for validation.\")\n",
        "\n",
        "\n",
        "        if stage == \"test\" or stage is None:\n",
        "            # Setup competition test dataset\n",
        "             print(f\"Setting up competition test dataset from: {self.test_pkl}\")\n",
        "             self.predict_dataset = AGNewsTestDataset(\n",
        "                 self.test_pkl,\n",
        "                 self.tokenizer,\n",
        "                 self.max_seq_length\n",
        "             )\n",
        "             print(f\"Loaded {len(self.predict_dataset)} samples for competition prediction.\")\n",
        "\n",
        "\n",
        "    def get_train_loader(self):\n",
        "        if not self.train_dataset:\n",
        "            self.setup(\"fit\")\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.data_collator # Use collator for dynamic padding\n",
        "        )\n",
        "\n",
        "    def get_val_loader(self):\n",
        "        if not self.val_dataset:\n",
        "            self.setup(\"validate\") # Or 'fit' if you always run setup completely\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.test_batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.data_collator # Use collator for dynamic padding\n",
        "        )\n",
        "\n",
        "    def get_competition_test_loader(self):\n",
        "        \"\"\"Gets the DataLoader for the competition's unlabelled test set.\"\"\"\n",
        "        if not self.predict_dataset:\n",
        "            self.setup(\"test\")\n",
        "        return DataLoader(\n",
        "            self.predict_dataset,\n",
        "            batch_size=self.test_batch_size,\n",
        "            shuffle=False, # Important: Keep order for submission\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.data_collator # Use collator for dynamic padding - it handles dicts well\n",
        "        )\n",
        "\n",
        "    def download_competition_data(self):\n",
        "        \"\"\"Downloads and extracts competition test data using Kaggle API.\"\"\"\n",
        "        if not os.path.exists(self.test_pkl):\n",
        "            print(f\"Competition test file not found at {self.test_pkl}. Attempting download...\")\n",
        "            os.makedirs(self.competition_path, exist_ok=True)\n",
        "            try:\n",
        "                from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "                api = KaggleApi()\n",
        "                api.authenticate() # Make sure kaggle.json is set up\n",
        "                api.competition_download_files(self.competition_name, path=self.competition_path)\n",
        "\n",
        "                if os.path.exists(self.zip_path):\n",
        "                    print(f\"Extracting {self.zip_path}...\")\n",
        "                    with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(self.competition_path)\n",
        "                    os.remove(self.zip_path) # Clean up the zip file\n",
        "                    print(\"Extraction complete.\")\n",
        "                else:\n",
        "                     print(f\"Warning: Zip file {self.zip_path} not found after download attempt.\")\n",
        "\n",
        "            except ImportError:\n",
        "                print(\"Warning: 'kaggle' library not found. Cannot download competition data automatically.\")\n",
        "                print(\"Please download the 'test_unlabelled.pkl' manually from the Kaggle competition page\")\n",
        "                print(f\"and place it in: {self.competition_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during Kaggle download/extraction: {e}\")\n",
        "                print(\"Please check your Kaggle API setup and competition name.\")\n",
        "\n",
        "        if not os.path.exists(self.test_pkl):\n",
        "            # Raise error only after attempting download\n",
        "            raise FileNotFoundError(\n",
        "                f\"Competition test file '{os.path.basename(self.test_pkl)}' not found in '{self.competition_path}'. \"\n",
        "                \"Please ensure it is downloaded and extracted correctly.\"\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Competition test file found: {self.test_pkl}\")\n"
      ],
      "metadata": {
        "id": "i-y0FkhJp-kG"
      },
      "id": "i-y0FkhJp-kG",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example configuration\n",
        "MODEL_ID = \"roberta-base\"\n",
        "COMPETITION_ID = \"deep-learning-spring-2025-project-2\" # Double-check this ID\n",
        "DATA_DIR = \"./agnews_data\"\n",
        "BATCH_SIZE = 8 # Small batch size for demo\n",
        "TEST_BATCH_SIZE = 16\n",
        "MAX_LEN = 128 # Shorter length for faster demo processing\n",
        "\n",
        "# Instantiate the data module\n",
        "data_module = AGNewsDataModule(\n",
        "    model_name_or_path=MODEL_ID,\n",
        "    data_dir=DATA_DIR,\n",
        "    competition_name=COMPETITION_ID,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    test_batch_size=TEST_BATCH_SIZE,\n",
        "    max_seq_length=MAX_LEN,\n",
        "    num_workers=0 # Set to 0 for easier debugging in __main__\n",
        ")\n",
        "\n",
        "data_module.prepare_data() # Downloads HF data and competition data if needed\n",
        "\n",
        "data_module.setup() # Sets up train, val, and test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "945d105ead994f76befbd0e82dc7795c",
            "f6d8c9b2eff24e10910c3ac09eb234b1",
            "c8ac90bb59f949d08f903fbd1a94e5a8",
            "f016b72d72d94010a0f6788251ed2842",
            "a2dc9fc7a2ff432db8fbecfa0b691c5d",
            "bf2c736851f64d6d8ca5df2e6629df39",
            "ad8cea3a91ea463cb09818b9526a8d51",
            "af827b8ed9824e89b13f570c760277b0",
            "0bd4c455124949af8851895001885897",
            "9f16e4c9098e45a2978753774e5e7f44",
            "36f1573e3efe48ebb54ede3764b4e867"
          ]
        },
        "id": "VBzMLw2oxvXV",
        "outputId": "c68f6fa7-30f5-42f4-ddf7-1bcff2847642"
      },
      "id": "VBzMLw2oxvXV",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking/downloading AGNEWS dataset from Hugging Face...\n",
            "Checking/downloading competition test data...\n",
            "Competition test file found: ./agnews_data/deep-learning-spring-2025-project-2/test_unlabelled.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "945d105ead994f76befbd0e82dc7795c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 108000 samples for training, 12000 for validation.\n",
            "Setting up competition test dataset from: ./agnews_data/deep-learning-spring-2025-project-2/test_unlabelled.pkl\n",
            "Pickle file contained a Hugging Face Dataset object.\n",
            "Successfully extracted 'text' column (8000 items).\n",
            "Loaded 8000 samples for competition prediction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Visualize Training Samples ---\n",
        "print(\"\\n--- Train Set Samples (First 5) ---\")\n",
        "try:\n",
        "    if data_module.train_dataset:\n",
        "        # Select the first 5 samples directly from the Hugging Face dataset\n",
        "        train_samples = data_module.train_dataset.select(range(min(5, len(data_module.train_dataset))))\n",
        "\n",
        "        train_data_for_df = []\n",
        "        for sample in train_samples:\n",
        "            text = data_module.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
        "            # Ensure 'label' exists, otherwise use a placeholder like None or -1\n",
        "            label = sample.get('label', None)\n",
        "            if isinstance(label, torch.Tensor):\n",
        "                  label = label.item() # Convert tensor to Python number\n",
        "            train_data_for_df.append({'Decoded Text': text, 'Label': label})\n",
        "\n",
        "        train_df = pd.DataFrame(train_data_for_df)\n",
        "        print(train_df)\n",
        "    else:\n",
        "        print(\"Train dataset not loaded or empty.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error displaying train samples: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kczrZ0BWqy1H",
        "outputId": "8ffa5f1a-0793-4ae1-8813-200b1a12e339"
      },
      "id": "kczrZ0BWqy1H",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Train Set Samples (First 5) ---\n",
            "                                        Decoded Text  Label\n",
            "0  Construction, Industrial Data Give Mixed Signa...      2\n",
            "1  Palestinians to See Arafat Despite Wife's Fury...      0\n",
            "2  The Rise and Fall of the Mayan Empire NASA sci...      3\n",
            "3  Icy couple to be the faces of 2006 Winter Game...      1\n",
            "4  Southwest expands Oakland Airport destinations...      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualize Validation Samples ---\n",
        "print(\"\\n--- Validation Set Samples (First 5) ---\")\n",
        "try:\n",
        "    if data_module.val_dataset:\n",
        "        # Select the first 5 samples directly from the Hugging Face dataset\n",
        "        val_samples = data_module.val_dataset.select(range(min(5, len(data_module.val_dataset))))\n",
        "\n",
        "        val_data_for_df = []\n",
        "        for sample in val_samples:\n",
        "            text = data_module.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
        "            # Ensure 'label' exists, otherwise use a placeholder like None or -1\n",
        "            label = sample.get('label', None)\n",
        "            if isinstance(label, torch.Tensor):\n",
        "                  label = label.item() # Convert tensor to Python number\n",
        "            val_data_for_df.append({'Decoded Text': text, 'Label': label})\n",
        "\n",
        "        val_df = pd.DataFrame(val_data_for_df)\n",
        "        print(val_df)\n",
        "    else:\n",
        "        print(\"Validation dataset not loaded or empty.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error displaying validation samples: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5djOy67q50y",
        "outputId": "48dc22e6-172f-4b39-97e1-d4a293471e06"
      },
      "id": "C5djOy67q50y",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Validation Set Samples (First 5) ---\n",
            "                                        Decoded Text  Label\n",
            "0  Security alert identifies Oracle holes Softwar...      3\n",
            "1  Annual Competition for Public Space Flight MOJ...      0\n",
            "2  Stocks lower on worries oil prices will start ...      2\n",
            "3  Alaska's Lone Elephant Getting Treadmill (AP) ...      3\n",
            "4  Yahoo! wants a slice of Desktop Search Market ...      3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Visualize Competition Test Samples ---\n",
        "print(\"\\n--- Competition Test Set Samples (First 5) ---\")\n",
        "try:\n",
        "    if data_module.predict_dataset:\n",
        "        test_data_for_df = []\n",
        "        # Iterate through the custom dataset using __getitem__\n",
        "        num_samples_to_show = min(5, len(data_module.predict_dataset))\n",
        "        for i in range(num_samples_to_show):\n",
        "            sample = data_module.predict_dataset[i] # Fetches the dictionary item\n",
        "            text = data_module.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
        "            # Ensure 'index' exists, otherwise use a placeholder like None or -1\n",
        "            original_index = sample.get('index', None)\n",
        "            test_data_for_df.append({'Decoded Text': text, 'Original Index': original_index})\n",
        "\n",
        "        test_df = pd.DataFrame(test_data_for_df)\n",
        "        print(test_df)\n",
        "    else:\n",
        "        print(\"Competition test dataset not loaded or empty.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error displaying competition test samples: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rNQ9-6Eq-gk",
        "outputId": "6b052198-c3c9-4976-f10a-2bd78c317abd"
      },
      "id": "0rNQ9-6Eq-gk",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Competition Test Set Samples (First 5) ---\n",
            "                                        Decoded Text  Original Index\n",
            "0  Remains of New Species of Hobbit-Sized Human F...               0\n",
            "1  Iran to cease negotiations with EU in case of ...               1\n",
            "2  Israel levels new accusations against Syria Wi...               2\n",
            "3  Enevo a Silicon Valley startup create self-pow...               3\n",
            "4  NBA owners have imposed a luxury tax change on...               4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import evaluate # Hugging Face evaluate library\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding # Make sure this is imported\n",
        ")\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "\n"
      ],
      "metadata": {
        "id": "htBNx68lqdrr"
      },
      "id": "htBNx68lqdrr",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nH5s2T44wRIR"
      },
      "id": "nH5s2T44wRIR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bse RoBERTa Model Import"
      ],
      "metadata": {
        "id": "RuSShyAL8SVp"
      },
      "id": "RuSShyAL8SVp"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c77caa05",
      "metadata": {
        "id": "c77caa05"
      },
      "outputs": [],
      "source": [
        "# Assume AGNewsDataModule is defined in another file or earlier in the script\n",
        "# from your_data_module_file import AGNewsDataModule\n",
        "\n",
        "# --- Configuration ---\n",
        "model_name = \"roberta-base\"\n",
        "num_labels = 4\n",
        "lora_r = 8\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "target_modules = [\"query\", \"value\"]\n",
        "output_dir = \"./results/roberta-lora-agnews\" # Directory to save checkpoints and logs\n",
        "training_log_dir = \"./logs/roberta-lora-agnews\" # Directory for TensorBoard/logging\n",
        "adapter_save_dir = \"./trained_adapters/roberta-lora-agnews\" # Directory to save final adapter\n",
        "\n",
        "# --- Hyperparameters for Training ---\n",
        "# These are crucial and require tuning!\n",
        "learning_rate = 2e-4 # LoRA might tolerate/need higher LR than full finetuning\n",
        "train_batch_size = 16 # Adjust based on GPU memory\n",
        "eval_batch_size = 32  # Adjust based on GPU memory\n",
        "num_train_epochs = 3  # Start with a few epochs, increase as needed\n",
        "weight_decay = 0.01\n",
        "warmup_ratio = 0.1 # Percentage of steps for learning rate warmup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load Base Model (as you did) ---\n",
        "print(f\"Loading base model '{model_name}'...\")\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "8c1823dd4d3e41d0913e5708b7c7892e",
            "168d0e769da64fb1b1948d2e2c2a41f9",
            "69fdb4c78f174696b1b34b1d0e51ff0e",
            "540202ceae8f47c9ae590b4c71975be0",
            "569083f6397c456581d2c6ad0137461e",
            "eb89eda85ef44a0593772105b83c1452",
            "c1b8ac865a15430596dfa74e3bd63d4f",
            "dec70835e8274587a6b41aa2a4f9e7cf",
            "5da6634312534dbcaa66a349092507cd",
            "9e591897c9964d18ac6419ed25b8360b",
            "26ac8e7a161c4be39130e202c65643e2"
          ]
        },
        "id": "dfoSRkq9wTa3",
        "outputId": "f3c3ab22-c527-4987-a1d8-723faedb03b0"
      },
      "id": "dfoSRkq9wTa3",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model 'roberta-base'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c1823dd4d3e41d0913e5708b7c7892e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Define LoRA Config (as you did) ---\n",
        "print(\"Defining LoRA configuration...\")\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    target_modules=target_modules,\n",
        "    lora_dropout=lora_dropout,\n",
        "    bias=\"none\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBfFThOjwfqI",
        "outputId": "5070a73b-7cef-4ad2-c5a3-506de067b618"
      },
      "id": "mBfFThOjwfqI",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defining LoRA configuration...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Apply LoRA to the model (as you did) ---\n",
        "print(\"Applying LoRA adapter to the model...\")\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters() # Verify parameter count is low\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VcoHYepwXKk",
        "outputId": "64e5aa3f-6b05-4475-adce-570900b03d13"
      },
      "id": "5VcoHYepwXKk",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying LoRA adapter to the model...\n",
            "trainable params: 888,580 || all params: 125,537,288 || trainable%: 0.7078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = data_module.get_train_loader().dataset # Get the underlying Dataset object\n",
        "val_dataset = data_module.get_val_loader().dataset     # Get the underlying Dataset object\n",
        "tokenizer = data_module.tokenizer                     # Get the tokenizer\n",
        "data_collator = data_module.data_collator             # Get the data collator"
      ],
      "metadata": {
        "id": "pVhzY7DawXTN"
      },
      "id": "pVhzY7DawXTN",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC_gG7Eewqqw",
        "outputId": "41aae974-7ef4-4345-e47d-2fe5eefde9a4"
      },
      "id": "WC_gG7Eewqqw",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 108000\n",
            "Validation dataset size: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Define Compute Metrics Function ---\n",
        "# Load the accuracy metric\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes accuracy on evaluation predictions.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    # 'predictions' are logits, convert to predicted class index\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    # Calculate accuracy\n",
        "    acc = accuracy_metric.compute(predictions=preds, references=labels)\n",
        "    return {\"accuracy\": acc[\"accuracy\"]}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c676d3d98aa84b8492e1a74ef8ba7ec2",
            "c1a52f19f7764667a4738180f82817fc",
            "5397426e71d94b8e8703ac2901de70a4",
            "f4c4666f185c405b89dd09c98a6480ab",
            "2dcc4ea65d52488a8551bac7c90a536d",
            "a237a616f03d4f28b66a34b6dd0bde9a",
            "da5ea0abcecb4fdab4340436589fa0fe",
            "a1403e13943d4504b47cb528d9ea8915",
            "9f4b9f0c60784614871f2e09c79d102a",
            "3a3002edb0464d61a875aa5b95458534",
            "75e19d26df8c4b179af6043e4b9e9960"
          ]
        },
        "id": "UzAGnMFQwXY7",
        "outputId": "a7ebfdf5-30fd-4569-9df9-5bd3ad9fbcc3"
      },
      "id": "UzAGnMFQwXY7",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c676d3d98aa84b8492e1a74ef8ba7ec2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Define Training Arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "    per_device_eval_batch_size=eval_batch_size,\n",
        "    weight_decay=weight_decay,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "\n",
        "    # Evaluation and Saving Strategy\n",
        "    eval_strategy=\"epoch\", # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",       # Save checkpoint at the end of each epoch\n",
        "    load_best_model_at_end=True, # Load the best model found during training\n",
        "    metric_for_best_model=\"accuracy\", # Use accuracy to determine the best model\n",
        "    greater_is_better=True,      # Higher accuracy is better\n",
        "\n",
        "    # Logging\n",
        "    logging_dir=training_log_dir,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,            # Log metrics every 50 steps\n",
        "\n",
        "    # Other potentially useful args\n",
        "    # fp16=True,                 # Enable mixed precision training if GPU supports it (requires accelerate)\n",
        "    # gradient_accumulation_steps=2, # If batch size needs to be effectively larger than fits in memory\n",
        "    report_to=\"tensorboard\",     # Report logs to TensorBoard (can also use \"wandb\")\n",
        "    save_total_limit=2,          # Keep only the last 2 checkpoints + the best one\n",
        "    # push_to_hub=False,         # Set to True to push model to Hugging Face Hub\n",
        ")"
      ],
      "metadata": {
        "id": "6MMBr27LwXb4"
      },
      "id": "6MMBr27LwXb4",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Initialize Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,                         # The PEFT model\n",
        "    args=training_args,                  # Training arguments\n",
        "    train_dataset=train_dataset,         # Training dataset\n",
        "    eval_dataset=val_dataset,            # Validation dataset\n",
        "    tokenizer=tokenizer,                 # Tokenizer (needed for padding/saving)\n",
        "    data_collator=data_collator,         # Data collator for dynamic padding\n",
        "    compute_metrics=compute_metrics,     # Function to compute metrics\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXmDmEkawXfL",
        "outputId": "1523e2d1-ca8f-4380-e453-eeb4ffa9a61e"
      },
      "id": "sXmDmEkawXfL",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-05433fed2876>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Start Training ---\n",
        "print(\"\\nStarting Training...\")\n",
        "train_result = trainer.train()\n",
        "# --- 9. Save Training Stats and Final Adapter ---\n",
        "print(\"\\nTraining finished. Saving metrics and final adapter...\")\n",
        "# Saves metrics like loss, learning rate, epoch, etc. to json file\n",
        "trainer.log_metrics(\"train\", train_result.metrics)\n",
        "trainer.save_metrics(\"train\", train_result.metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "vBfHlfaZwXib",
        "outputId": "f4a6b747-2684-4063-8b5d-24b93691f784"
      },
      "id": "vBfHlfaZwXib",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='818' max='20250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  818/20250 02:19 < 55:30, 5.84 it/s, Epoch 0.12/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained LoRA adapter weights explicitly\n",
        "# This saves only the adapter weights, which is the goal of PEFT\n",
        "model.save_pretrained(adapter_save_dir)\n",
        "# You might also want to save the tokenizer with the adapter for easy loading later\n",
        "tokenizer.save_pretrained(adapter_save_dir)\n",
        "print(f\"LoRA adapter weights saved to: {adapter_save_dir}\")"
      ],
      "metadata": {
        "id": "QRx5NzMAxEY4"
      },
      "id": "QRx5NzMAxEY4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 10. Evaluate Final Model (Optional but recommended) ---\n",
        "print(\"\\nEvaluating the best model on the validation set...\")\n",
        "eval_metrics = trainer.evaluate(eval_dataset=val_dataset) # Use the same validation set\n",
        "trainer.log_metrics(\"eval\", eval_metrics)\n",
        "trainer.save_metrics(\"eval\", eval_metrics)\n",
        "print(f\"Final Evaluation Metrics: {eval_metrics}\")\n",
        "\n",
        "print(\"\\nLoRA Training Setup Complete.\")"
      ],
      "metadata": {
        "id": "1SKBrfk_wXlS"
      },
      "id": "1SKBrfk_wXlS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "pmj-gNGw8fNj"
      },
      "id": "pmj-gNGw8fNj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ed99d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15ed99d7",
        "outputId": "236445da-47b0-4fd4-8da4-c52ee3d76718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"lora_roberta_agnews\",\n",
        "#     eval_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     logging_strategy=\"steps\",\n",
        "#     logging_steps=100,\n",
        "#     per_device_train_batch_size=32,\n",
        "#     per_device_eval_batch_size=32,\n",
        "#     num_train_epochs=1,\n",
        "#     learning_rate=1e-4,\n",
        "#     load_best_model_at_end=True\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=test_dataset\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00998591",
      "metadata": {
        "id": "00998591"
      },
      "outputs": [],
      "source": [
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "XjcHakFx8h0K"
      },
      "id": "XjcHakFx8h0K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc736f26",
      "metadata": {
        "id": "dc736f26"
      },
      "outputs": [],
      "source": [
        "#basic metrics here\n",
        "\n",
        "''' metrics = trainer.evaluate()\n",
        "print(metrics) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b990c7c",
      "metadata": {
        "id": "8b990c7c"
      },
      "outputs": [],
      "source": [
        "''' training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    from datasets import load_metric\n",
        "    metric = load_metric(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,  # or a validation split if you prefer\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train() '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbvqHQbL1eN0"
      },
      "id": "UbvqHQbL1eN0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02993a71",
      "metadata": {
        "id": "02993a71"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"lora-roberta-agnews\")\n",
        "# tokenizer.save_pretrained(\"lora-roberta-agnews\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "945d105ead994f76befbd0e82dc7795c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6d8c9b2eff24e10910c3ac09eb234b1",
              "IPY_MODEL_c8ac90bb59f949d08f903fbd1a94e5a8",
              "IPY_MODEL_f016b72d72d94010a0f6788251ed2842"
            ],
            "layout": "IPY_MODEL_a2dc9fc7a2ff432db8fbecfa0b691c5d"
          }
        },
        "f6d8c9b2eff24e10910c3ac09eb234b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2c736851f64d6d8ca5df2e6629df39",
            "placeholder": "​",
            "style": "IPY_MODEL_ad8cea3a91ea463cb09818b9526a8d51",
            "value": "Map: 100%"
          }
        },
        "c8ac90bb59f949d08f903fbd1a94e5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af827b8ed9824e89b13f570c760277b0",
            "max": 7600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bd4c455124949af8851895001885897",
            "value": 7600
          }
        },
        "f016b72d72d94010a0f6788251ed2842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f16e4c9098e45a2978753774e5e7f44",
            "placeholder": "​",
            "style": "IPY_MODEL_36f1573e3efe48ebb54ede3764b4e867",
            "value": " 7600/7600 [00:01&lt;00:00, 5687.18 examples/s]"
          }
        },
        "a2dc9fc7a2ff432db8fbecfa0b691c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2c736851f64d6d8ca5df2e6629df39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8cea3a91ea463cb09818b9526a8d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af827b8ed9824e89b13f570c760277b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd4c455124949af8851895001885897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f16e4c9098e45a2978753774e5e7f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36f1573e3efe48ebb54ede3764b4e867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c1823dd4d3e41d0913e5708b7c7892e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_168d0e769da64fb1b1948d2e2c2a41f9",
              "IPY_MODEL_69fdb4c78f174696b1b34b1d0e51ff0e",
              "IPY_MODEL_540202ceae8f47c9ae590b4c71975be0"
            ],
            "layout": "IPY_MODEL_569083f6397c456581d2c6ad0137461e"
          }
        },
        "168d0e769da64fb1b1948d2e2c2a41f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb89eda85ef44a0593772105b83c1452",
            "placeholder": "​",
            "style": "IPY_MODEL_c1b8ac865a15430596dfa74e3bd63d4f",
            "value": "model.safetensors: 100%"
          }
        },
        "69fdb4c78f174696b1b34b1d0e51ff0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec70835e8274587a6b41aa2a4f9e7cf",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5da6634312534dbcaa66a349092507cd",
            "value": 498818054
          }
        },
        "540202ceae8f47c9ae590b4c71975be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e591897c9964d18ac6419ed25b8360b",
            "placeholder": "​",
            "style": "IPY_MODEL_26ac8e7a161c4be39130e202c65643e2",
            "value": " 499M/499M [00:06&lt;00:00, 99.0MB/s]"
          }
        },
        "569083f6397c456581d2c6ad0137461e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb89eda85ef44a0593772105b83c1452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b8ac865a15430596dfa74e3bd63d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dec70835e8274587a6b41aa2a4f9e7cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da6634312534dbcaa66a349092507cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e591897c9964d18ac6419ed25b8360b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ac8e7a161c4be39130e202c65643e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c676d3d98aa84b8492e1a74ef8ba7ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1a52f19f7764667a4738180f82817fc",
              "IPY_MODEL_5397426e71d94b8e8703ac2901de70a4",
              "IPY_MODEL_f4c4666f185c405b89dd09c98a6480ab"
            ],
            "layout": "IPY_MODEL_2dcc4ea65d52488a8551bac7c90a536d"
          }
        },
        "c1a52f19f7764667a4738180f82817fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a237a616f03d4f28b66a34b6dd0bde9a",
            "placeholder": "​",
            "style": "IPY_MODEL_da5ea0abcecb4fdab4340436589fa0fe",
            "value": "Downloading builder script: 100%"
          }
        },
        "5397426e71d94b8e8703ac2901de70a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1403e13943d4504b47cb528d9ea8915",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f4b9f0c60784614871f2e09c79d102a",
            "value": 4203
          }
        },
        "f4c4666f185c405b89dd09c98a6480ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3002edb0464d61a875aa5b95458534",
            "placeholder": "​",
            "style": "IPY_MODEL_75e19d26df8c4b179af6043e4b9e9960",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 229kB/s]"
          }
        },
        "2dcc4ea65d52488a8551bac7c90a536d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a237a616f03d4f28b66a34b6dd0bde9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5ea0abcecb4fdab4340436589fa0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1403e13943d4504b47cb528d9ea8915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4b9f0c60784614871f2e09c79d102a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a3002edb0464d61a875aa5b95458534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e19d26df8c4b179af6043e4b9e9960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}